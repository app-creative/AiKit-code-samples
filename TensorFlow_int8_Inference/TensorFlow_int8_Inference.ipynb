{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Getting Started with TensorFlow low-precision int8 inference\n",
    "\n",
    "This code sample will serve as a sample use case to perform low precision int8 inference on a synthetic data implementing a ResNet50 pre-trained model. The pre-trained model published as part of Intel Model Zoo will be used in this sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import statements\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download Intel's pretrained resnet50 model\n",
    "try:\n",
    "    !wget https://storage.googleapis.com/intel-optimized-tensorflow/models/resnet50_int8_pretrained_model.pb\n",
    "except:\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve('https://storage.googleapis.com/intel-optimized-tensorflow/models/resnet50_int8_pretrained_model.pb', 'resnet50_int8_pretrained_model.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a synthetic dataset of size 244x244.\n",
    "It is important to set optimial batch_size, MKL run-time settings, TensorFlow's inter-intra number of threads to enable compute and data layer optimizations. We have identified  optimial settings for popular topologies including ResNet50 to maximize CPU utlization. For more details on Run-time settings refer to blogs [maximize CPU performance](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference), [Intel Model Zoo tutorials](https://github.com/IntelAI/models/tree/master/docs). \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    physical_cores= !lscpu -b -p=Core,Socket | grep -v '^#' | sort -u | wc -l\n",
    "except:\n",
    "    physical_cores = [str(os.cpu_count())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"resnet50_int8_pretrained_model.pb\"\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "batch_size = 64\n",
    "input_layer = \"input\" # input tensor name from the stored graph\n",
    "output_layer = \"predict\"# input tensor name to be computed\n",
    "warmup_steps = 10\n",
    "steps = 50\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]= physical_cores[0]\n",
    "num_inter_threads = 2\n",
    "num_intra_threads = int(physical_cores[0])\n",
    "data_config = tf.ConfigProto()\n",
    "data_config.intra_op_parallelism_threads = 16 \n",
    "data_config.inter_op_parallelism_threads = 14 \n",
    "data_config.use_per_session_threads = 1\n",
    "\n",
    "infer_config = tf.ConfigProto()\n",
    "infer_config.intra_op_parallelism_threads = num_intra_threads\n",
    "infer_config.inter_op_parallelism_threads = num_inter_threads\n",
    "infer_config.use_per_session_threads = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data graph, and infer graph from pre-trained int8 resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_graph = tf.Graph()\n",
    "with data_graph.as_default():\n",
    "    input_shape = [batch_size, input_height, input_width, 3]\n",
    "    images = tf.random.uniform(input_shape, 0.0, 255.0, dtype=tf.float32, name='synthetic_images')\n",
    "\n",
    "infer_graph = tf.Graph()\n",
    "with infer_graph.as_default():\n",
    "    graph_def = tf.GraphDef()\n",
    "    with open(model_file, \"rb\") as f:\n",
    "      graph_def.ParseFromString(f.read())\n",
    "    tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data and infer sessions for optimized data access and graph computation configured with best thread settings for Resnet50 and run warm-up steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = infer_graph.get_tensor_by_name(input_layer + \":0\")\n",
    "output_tensor = infer_graph.get_tensor_by_name(output_layer + \":0\")\n",
    "tf.global_variables_initializer()\n",
    "\n",
    "data_sess = tf.Session(graph=data_graph, config=data_config)\n",
    "infer_sess = tf.Session(graph=infer_graph, config=infer_config)\n",
    "\n",
    "print(\"[Running warmup steps...]\")\n",
    "step_total_time = 0\n",
    "step_total_images = 0\n",
    "\n",
    "for t in range(warmup_steps):\n",
    "    data_start_time = time.time()\n",
    "    image_data = data_sess.run(images)\n",
    "    data_load_time = time.time() - data_start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    step_total_time += elapsed_time\n",
    "    step_total_images += batch_size\n",
    "\n",
    "    if ((t + 1) % 10 == 0):\n",
    "      print(\"steps = {0}, {1} images/sec\"\n",
    "            \"\".format(t + 1, step_total_images / step_total_time))\n",
    "      step_total_time = 0\n",
    "      step_total_images = 0\n",
    "\n",
    "total_time = 0\n",
    "total_images = 0\n",
    "\n",
    "step_total_time = 0\n",
    "step_total_images = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training steps with batch size 64 to measure average throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[Running benchmark steps...]\")\n",
    "for t in range(steps):\n",
    "    try:\n",
    "      data_start_time = time.time()\n",
    "      image_data = data_sess.run(images)\n",
    "      data_load_time = time.time() - data_start_time\n",
    "\n",
    "      start_time = time.time()\n",
    "      infer_sess.run(output_tensor, {input_tensor: image_data})\n",
    "      elapsed_time = time.time() - start_time\n",
    "\n",
    "\n",
    "      total_time += elapsed_time\n",
    "      total_images += batch_size\n",
    "\n",
    "      step_total_time += elapsed_time\n",
    "      step_total_images += batch_size\n",
    "\n",
    "      if ((t + 1) % 10 == 0):\n",
    "        print(\"steps = {0}, {1} images/sec\"\n",
    "              \"\".format(t + 1, step_total_images / step_total_time))\n",
    "        step_total_time = 0\n",
    "        step_total_images = 0\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "      print(\"Running out of images from dataset.\")\n",
    "      break\n",
    "\n",
    "print(\"Average throughput for batch size {0}: {1} images/sec\".format(batch_size, total_images / total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[CODE_SAMPLE_COMPLETED_SUCCESFULLY]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_2] *",
   "language": "python",
   "name": "conda-env-tf_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
